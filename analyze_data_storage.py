#!/usr/bin/env python3
"""
å†å²è®°å½•æ•°æ®å­˜å‚¨åˆ†æè„šæœ¬
"""

import os
import sys
import json
import glob
from pathlib import Path
from datetime import datetime

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

def analyze_file_storage():
    """åˆ†ææ–‡ä»¶å­˜å‚¨çš„å†å²è®°å½•"""
    print("ğŸ“ æ–‡ä»¶å­˜å‚¨åˆ†æ")
    print("=" * 50)
    
    # æ£€æŸ¥dataç›®å½•
    data_dir = "./data"
    if os.path.exists(data_dir):
        print(f"âœ… dataç›®å½•å­˜åœ¨: {data_dir}")
        
        # æŸ¥æ‰¾æ‰€æœ‰progressæ–‡ä»¶
        progress_files = glob.glob(os.path.join(data_dir, "progress_*.json"))
        print(f"ğŸ“Š æ‰¾åˆ° {len(progress_files)} ä¸ªè¿›åº¦æ–‡ä»¶")
        
        for i, file_path in enumerate(progress_files, 1):
            try:
                filename = os.path.basename(file_path)
                file_stat = os.stat(file_path)
                file_time = datetime.fromtimestamp(file_stat.st_mtime)
                
                with open(file_path, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                
                analysis_id = data.get('analysis_id', 'æœªçŸ¥')
                status = data.get('status', 'æœªçŸ¥')
                stock_symbol = 'æœªçŸ¥'
                
                # å°è¯•ä»raw_resultsè·å–è‚¡ç¥¨ä¿¡æ¯
                raw_results = data.get('raw_results', {})
                if isinstance(raw_results, dict):
                    stock_symbol = raw_results.get('stock_symbol', stock_symbol)
                
                print(f"  {i}. æ–‡ä»¶: {filename}")
                print(f"     è‚¡ç¥¨: {stock_symbol}")
                print(f"     çŠ¶æ€: {status}")
                print(f"     ä¿®æ”¹æ—¶é—´: {file_time.strftime('%Y-%m-%d %H:%M:%S')}")
                print(f"     æ–‡ä»¶å¤§å°: {file_stat.st_size} å­—èŠ‚")
                print()
                
            except Exception as e:
                print(f"  âŒ è¯»å–æ–‡ä»¶å¤±è´¥: {filename} - {e}")
    else:
        print(f"âŒ dataç›®å½•ä¸å­˜åœ¨: {data_dir}")
    
    # æ£€æŸ¥resultsç›®å½•
    results_dir = "./results"
    if os.path.exists(results_dir):
        print(f"\nğŸ“‹ resultsç›®å½•å­˜åœ¨: {results_dir}")
        
        # é€’å½’æŸ¥æ‰¾æ‰€æœ‰åˆ†æç»“æœæ–‡ä»¶
        result_files = []
        for root, dirs, files in os.walk(results_dir):
            for file in files:
                if file.endswith(('.json', '.md', '.txt')):
                    result_files.append(os.path.join(root, file))
        
        print(f"ğŸ“Š æ‰¾åˆ° {len(result_files)} ä¸ªç»“æœæ–‡ä»¶")
        
        if result_files:
            print("ç»“æœæ–‡ä»¶è¯¦æƒ…:")
            for i, file_path in enumerate(result_files[:10], 1):  # åªæ˜¾ç¤ºå‰10ä¸ª
                try:
                    filename = os.path.basename(file_path)
                    dir_name = os.path.basename(os.path.dirname(file_path))
                    file_stat = os.stat(file_path)
                    file_time = datetime.fromtimestamp(file_stat.st_mtime)
                    
                    print(f"  {i}. ç›®å½•: {dir_name}")
                    print(f"     æ–‡ä»¶: {filename}")
                    print(f"     ä¿®æ”¹æ—¶é—´: {file_time.strftime('%Y-%m-%d %H:%M:%S')}")
                    print(f"     æ–‡ä»¶å¤§å°: {file_stat.st_size} å­—èŠ‚")
                    print()
                    
                except Exception as e:
                    print(f"  âŒ è¯»å–æ–‡ä»¶ä¿¡æ¯å¤±è´¥: {file_path} - {e}")
    else:
        print(f"\nâŒ resultsç›®å½•ä¸å­˜åœ¨: {results_dir}")


def analyze_redis_storage():
    """åˆ†æRediså­˜å‚¨çš„å†å²è®°å½•"""
    print("\nğŸ”„ Rediså­˜å‚¨åˆ†æ")
    print("=" * 50)
    
    try:
        redis_enabled = os.getenv('REDIS_ENABLED', 'false').lower() == 'true'
        
        if not redis_enabled:
            print("âŒ Redisæœªå¯ç”¨")
            return
        
        import redis
        
        # ä»ç¯å¢ƒå˜é‡è·å–Redisé…ç½®
        redis_host = os.getenv('REDIS_HOST', 'localhost')
        redis_port = int(os.getenv('REDIS_PORT', 6379))
        redis_password = os.getenv('REDIS_PASSWORD', None)
        redis_db = int(os.getenv('REDIS_DB', 0))

        # åˆ›å»ºRedisè¿æ¥
        if redis_password:
            redis_client = redis.Redis(
                host=redis_host,
                port=redis_port,
                password=redis_password,
                db=redis_db,
                decode_responses=True
            )
        else:
            redis_client = redis.Redis(
                host=redis_host,
                port=redis_port,
                db=redis_db,
                decode_responses=True
            )

        # æµ‹è¯•è¿æ¥
        redis_client.ping()
        print(f"âœ… Redisè¿æ¥æˆåŠŸ: {redis_host}:{redis_port} (æ•°æ®åº“: {redis_db})")
        
        # æŸ¥æ‰¾æ‰€æœ‰progressé”®
        keys = redis_client.keys("progress:*")
        print(f"ğŸ“Š æ‰¾åˆ° {len(keys)} ä¸ªRedisè®°å½•")
        
        for i, key in enumerate(keys, 1):
            try:
                data = redis_client.get(key)
                if data:
                    progress_data = json.loads(data)
                    analysis_id = key.replace('progress:', '')
                    status = progress_data.get('status', 'æœªçŸ¥')
                    last_update = progress_data.get('last_update', 0)
                    
                    stock_symbol = 'æœªçŸ¥'
                    raw_results = progress_data.get('raw_results', {})
                    if isinstance(raw_results, dict):
                        stock_symbol = raw_results.get('stock_symbol', stock_symbol)
                    
                    if last_update:
                        update_time = datetime.fromtimestamp(last_update)
                        update_str = update_time.strftime('%Y-%m-%d %H:%M:%S')
                    else:
                        update_str = 'æœªçŸ¥æ—¶é—´'
                    
                    print(f"  {i}. é”®: {key}")
                    print(f"     è‚¡ç¥¨: {stock_symbol}")
                    print(f"     çŠ¶æ€: {status}")
                    print(f"     æ›´æ–°æ—¶é—´: {update_str}")
                    print()
                    
            except Exception as e:
                print(f"  âŒ è§£æRedisè®°å½•å¤±è´¥: {key} - {e}")
                
        # æ£€æŸ¥TTL
        if keys:
            sample_key = keys[0]
            ttl = redis_client.ttl(sample_key)
            if ttl > 0:
                print(f"â° è®°å½•è¿‡æœŸæ—¶é—´: {ttl} ç§’")
            elif ttl == -1:
                print(f"â™¾ï¸ è®°å½•æ°¸ä¸è¿‡æœŸ")
            else:
                print(f"âš ï¸ è®°å½•å·²è¿‡æœŸæˆ–ä¸å­˜åœ¨")
        
    except ImportError:
        print("âŒ Redisåº“æœªå®‰è£…")
    except Exception as e:
        print(f"âŒ Redisè¿æ¥å¤±è´¥: {e}")


def analyze_data_retention():
    """åˆ†ææ•°æ®ä¿ç•™æƒ…å†µ"""
    print("\nğŸ“… æ•°æ®ä¿ç•™åˆ†æ")
    print("=" * 50)
    
    # æ£€æŸ¥æ˜¨å¤©çš„æ•°æ®
    from datetime import date, timedelta
    yesterday = date.today() - timedelta(days=1)
    today = date.today()
    
    print(f"ğŸ“† ä»Šå¤©æ—¥æœŸ: {today}")
    print(f"ğŸ“† æ˜¨å¤©æ—¥æœŸ: {yesterday}")
    
    # æŸ¥æ‰¾å¯èƒ½çš„æ˜¨å¤©æ•°æ®
    data_patterns = [
        f"./data/*{yesterday.strftime('%Y%m%d')}*",
        f"./data/*{yesterday.strftime('%Y-%m-%d')}*", 
        f"./data/*{yesterday.strftime('%Y%m%d')}*",
        f"./results/*{yesterday.strftime('%Y%m%d')}*",
        f"./results/*{yesterday.strftime('%Y-%m-%d')}*"
    ]
    
    found_yesterday_files = []
    for pattern in data_patterns:
        files = glob.glob(pattern)
        found_yesterday_files.extend(files)
    
    if found_yesterday_files:
        print(f"âœ… æ‰¾åˆ° {len(found_yesterday_files)} ä¸ªæ˜¨å¤©çš„æ–‡ä»¶:")
        for file in found_yesterday_files:
            print(f"  - {file}")
    else:
        print("âŒ æœªæ‰¾åˆ°æ˜¨å¤©çš„æ•°æ®æ–‡ä»¶")
    
    # åˆ†æå¯èƒ½çš„æ•°æ®ä¸¢å¤±åŸå› 
    print("\nğŸ” å¯èƒ½çš„æ•°æ®ä¸¢å¤±åŸå› :")
    print("1. Redis TTLè¿‡æœŸ - Redisè®°å½•é»˜è®¤1å°æ—¶è¿‡æœŸ")
    print("2. æ–‡ä»¶å­˜å‚¨ä½ç½®å˜æ›´ - æ£€æŸ¥æ˜¯å¦å­˜å‚¨åœ¨å…¶ä»–ç›®å½•")
    print("3. æ•°æ®åº“åˆ‡æ¢ - Redisæ•°æ®åº“ç¼–å·å˜æ›´")
    print("4. ç¼“å­˜æ¸…ç† - ç³»ç»Ÿæˆ–æ‰‹åŠ¨æ¸…ç†äº†ç¼“å­˜æ•°æ®")
    print("5. è¿›ç¨‹é‡å¯ - æœåŠ¡é‡å¯å¯¼è‡´å†…å­˜æ•°æ®ä¸¢å¤±")


def provide_solutions():
    """æä¾›è§£å†³æ–¹æ¡ˆ"""
    print("\nğŸ’¡ è§£å†³æ–¹æ¡ˆå»ºè®®")
    print("=" * 50)
    
    print("ğŸ”§ ç«‹å³å¯æ‰§è¡Œçš„è§£å†³æ–¹æ¡ˆ:")
    print("1. å¢åŠ Redis TTLæ—¶é—´ - ä¿®æ”¹è¿‡æœŸæ—¶é—´ä¸º7å¤©æˆ–æ›´é•¿")
    print("2. å¯ç”¨æ–‡ä»¶æŒä¹…åŒ– - ç¡®ä¿æ‰€æœ‰åˆ†æéƒ½ä¿å­˜åˆ°æ–‡ä»¶")
    print("3. å¤‡ä»½æœºåˆ¶ - å®šæœŸå¤‡ä»½é‡è¦çš„åˆ†æç»“æœ")
    print("4. æ•°æ®æ¢å¤ - æ£€æŸ¥å…¶ä»–å¯èƒ½çš„å­˜å‚¨ä½ç½®")
    
    print("\nğŸ“‹ å…·ä½“æ“ä½œæ­¥éª¤:")
    print("â€¢ ä¿®æ”¹Redis TTL: åœ¨async_progress_tracker.pyä¸­è°ƒæ•´setexæ—¶é—´")
    print("â€¢ æ£€æŸ¥resultsç›®å½•: æŸ¥çœ‹æ˜¯å¦æœ‰å®Œæ•´çš„åˆ†ææŠ¥å‘Š")
    print("â€¢ æ¢å¤æ–‡ä»¶å­˜å‚¨: ç¡®ä¿æ‰€æœ‰åˆ†æéƒ½ä¼šä¿å­˜åˆ°æœ¬åœ°æ–‡ä»¶")
    print("â€¢ å¢å¼ºæ•°æ®æŒä¹…åŒ–: åŒæ—¶ä½¿ç”¨Rediså’Œæ–‡ä»¶åŒé‡å­˜å‚¨")


if __name__ == "__main__":
    print("ğŸ” TradingAgents-CN å†å²è®°å½•æ•°æ®åˆ†æ")
    print("=" * 60)
    
    # åŠ è½½ç¯å¢ƒå˜é‡
    try:
        from dotenv import load_dotenv
        load_dotenv()
    except ImportError:
        # æ‰‹åŠ¨è®¾ç½®Redisé…ç½®
        os.environ.setdefault('REDIS_ENABLED', 'true')
        os.environ.setdefault('REDIS_HOST', 'localhost')
        os.environ.setdefault('REDIS_PORT', '6379')
        os.environ.setdefault('REDIS_DB', '1')
    
    # æ‰§è¡Œåˆ†æ
    analyze_file_storage()
    analyze_redis_storage()
    analyze_data_retention()
    provide_solutions()
    
    print("\n" + "=" * 60)
    print("ğŸ“Š æ•°æ®åˆ†æå®Œæˆ")